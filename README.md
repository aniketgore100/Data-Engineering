# Data Engineering Essentials - Code Repository

Welcome to the **Data Engineering Essentials** repository. This repo contains the code, scripts, and resources used throughout the **Hands-On**.

## Table of Contents

### Section 1: Introduction to Data Engineering Essentials using SQL, Python, and PySpark  
### Section 2: Getting Started with SQL for Data Engineering  
### Section 3: Setup Tools for Data Engineering Essentials  
### Section 4: Setup Application Tables and Data in Postgres Database  
### Section 5: Writing Basic SQL Queries  
### Section 6: Cumulative Aggregations and Ranking in SQL Queries  
### Section 7: SQL Troubleshooting and Debugging Guide  
### Section 8: Performance Tuning of SQL Queries  
### Section 9: Exercises for Basic SQL Queries  
### Section 10: Solutions for Basic SQL Queries  
### Section 11: Getting Started with Python  
### Section 12: Python Collections for Data Engineering  
### Section 13: Data Processing using Pandas Dataframe APIs  
### Section 14: Project 1 - File Format Converter using Python  
### Section 15: Project 2 - Files to Database Loader  
### Section 16: Troubleshooting and Debugging Python Issues  
### Section 17: Performance Tuning of Python Applications  
### Section 18: Getting Started with GCP  
### Section 19: Overview of Big Data and Data Lakes  
### Section 20: Overview of Spark and Spark Architecture  
### Section 21: Setup Databricks Environment using GCP  
### Section 22: Basic Transformations using Spark SQL  
### Section 23: Create Delta Tables using Spark SQL  
### Section 24: Pre-Defined Functions in Spark SQL  
### Section 25: Setup Spark Metastore Tables for Basic Transformations  
### Section 26: Filtering Data using Spark SQL Queries  
### Section 27: Aggregations using Spark SQL Queries  
### Section 28: Joins using Spark SQL Queries  
### Section 29: Sorting using Spark SQL Queries  
### Section 30: Copy Query Results into Spark Metastore Tables  
### Section 31: Ranking using Spark SQL Windowing Functions  
### Section 32: Processing JSON like Data using Spark SQL  
### Section 33: Getting Started with PySpark Data Frame APIs  
### Section 34: Create Spark Data Frames using PySpark Data Frame APIs  
### Section 35: Basic Transformations using PySpark Data Frame APIs  
### Section 36: Joining Data using Spark Data Frame APIs  
### Section 37: Ranking using PySpark Data Frame APIs  
### Section 38: Integration of Spark SQL and PySpark Data Frame APIs  
### Section 39: ELT Data Pipelines using Databricks  
### Section 40: Performance Tuning of Spark - Catalyst Optimizer  
### Section 41: Performance Tuning of Spark - Cluster Configuration  
### Section 42: Performance Tuning while Inferring Schema from CSV or JSON files  
### Section 43: Performance Tuning using Columnar File Format and Partitioning Strategy  
### Section 44: Setup Hadoop and Spark Cluster using Dataproc  
### Section 45: Recap of Important Linux Commands for Data Engineering  
### Section 46: Mastering Hadoop HDFS Commands and Concepts  
### Section 47: Build Hive Applications in Hadoop and Spark Clusters  
### Section 48: Getting Started with Spark SQL on Hadoop and Spark Cluster  
### Section 49: Build Real-Time Applications using Spark SQL with Shell Wrapper  
### Section 50: Getting Started with PySpark on Hadoop and Spark Cluster  
### Section 51: Submitting Python-based Spark Applications  
### Section 52: Logging in Python-based Spark Applications  
### Section 53: Performance Tuning of Spark Applications on Hadoop and Spark  
